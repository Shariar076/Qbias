{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f8595ab-ad00-435e-9d18-f92b0993609e",
   "metadata": {},
   "source": [
    "## Import of required Modules\n",
    "Make sure, that the imported moduls are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911b1609-a4df-4311-92b5-67b1ac3d3957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "from IPython.display import clear_output \n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b078c40-20cc-46c4-9a09-2947812fcfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc4c60-25aa-4d46-9d40-47b32a7e6c4f",
   "metadata": {},
   "source": [
    "### Settings\n",
    "change the settings to assert the scraper runs on your system. We reccomend to change the wait_time to a higher value if you run the scraper on a slower system or internet connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a51084c-dea2-4290-adb5-0e07dfefda02",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_time = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d1a88-6955-4e93-a558-54a8488e7697",
   "metadata": {},
   "source": [
    "#### set up Selenium and Chrome Driver \n",
    "We use selenium with Chrome and tested the scraper with the chromedriver. You need the latest version of the driver from https://chromedriver.chromium.org/. Alternatively, change to the driver to a driver of your preferance.\n",
    "We set up the scraper to run in the background, if you wish to run it in regular window mode, remove the line  \"chrome_options.add_argument(\"--headless\")\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6234d-8171-4a69-8547-4247ae6d3453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chromedriver setup\n",
    "\n",
    "# serv = Service(r'driver/chromedriver') #path from 'which chromedriver'\n",
    "\n",
    "# test driver\n",
    "# for headless chrome mode\n",
    "# chrome_options = Options()\n",
    "\n",
    "# remove this line if you do not wish to run in background \n",
    "# chrome_options.add_argument(\"--headless\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d2c30e",
   "metadata": {},
   "source": [
    "## Retrieve news source bias information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18316719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News Source</th>\n",
       "      <th>Link</th>\n",
       "      <th>AllSides Bias Rating</th>\n",
       "      <th>Community feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABC News (Online)</td>\n",
       "      <td>https://www.allsides.com/news-source/abc-news-...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>Community strongly agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AlterNet</td>\n",
       "      <td>https://www.allsides.com/news-source/alternet-...</td>\n",
       "      <td>left</td>\n",
       "      <td>Community absolutely agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associated Press</td>\n",
       "      <td>https://www.allsides.com/news-source/associate...</td>\n",
       "      <td>left</td>\n",
       "      <td>Community somewhat agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Associated Press Fact Check</td>\n",
       "      <td>https://www.allsides.com/news-source/ap-fact-c...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>Community somewhat disagrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Axios</td>\n",
       "      <td>https://www.allsides.com/news-source/axios</td>\n",
       "      <td>left-center</td>\n",
       "      <td>Community somewhat disagrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BBC News</td>\n",
       "      <td>https://www.allsides.com/news-source/bbc-news-...</td>\n",
       "      <td>center</td>\n",
       "      <td>Community somewhat agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>https://www.allsides.com/news-source/bloomberg...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>Community somewhat disagrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Breitbart News</td>\n",
       "      <td>https://www.allsides.com/news-source/breitbart</td>\n",
       "      <td>right</td>\n",
       "      <td>Community absolutely agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Insider</td>\n",
       "      <td>https://www.allsides.com/news-source/insider-m...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>Community somewhat disagrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BuzzFeed News</td>\n",
       "      <td>https://www.allsides.com/news-source/buzzfeed-...</td>\n",
       "      <td>left</td>\n",
       "      <td>Community strongly agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CBS News (Online)</td>\n",
       "      <td>https://www.allsides.com/news-source/cbs-news-...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>Community somewhat agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Christian Science Monitor</td>\n",
       "      <td>https://www.allsides.com/news-source/christian...</td>\n",
       "      <td>center</td>\n",
       "      <td>Community somewhat disagrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CNN Digital</td>\n",
       "      <td>https://www.allsides.com/news-source/cnn-media...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>Community somewhat agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Daily Beast</td>\n",
       "      <td>https://www.allsides.com/news-source/daily-bea...</td>\n",
       "      <td>left</td>\n",
       "      <td>Community absolutely agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Daily Mail</td>\n",
       "      <td>https://www.allsides.com/news-source/daily-mail</td>\n",
       "      <td>right</td>\n",
       "      <td>Community agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Democracy Now!</td>\n",
       "      <td>https://www.allsides.com/news-source/democracy...</td>\n",
       "      <td>left</td>\n",
       "      <td>Community absolutely agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Forbes</td>\n",
       "      <td>https://www.allsides.com/news-source/forbes</td>\n",
       "      <td>center</td>\n",
       "      <td>Community somewhat agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fox News (Opinion)</td>\n",
       "      <td>https://www.allsides.com/news-source/fox-news-...</td>\n",
       "      <td>right</td>\n",
       "      <td>Community absolutely agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fox News Digital</td>\n",
       "      <td>https://www.allsides.com/news-source/fox-news-...</td>\n",
       "      <td>right</td>\n",
       "      <td>Community somewhat agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HuffPost</td>\n",
       "      <td>https://www.allsides.com/news-source/huffpost-...</td>\n",
       "      <td>left</td>\n",
       "      <td>Community agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mother Jones</td>\n",
       "      <td>https://www.allsides.com/news-source/mother-jo...</td>\n",
       "      <td>left</td>\n",
       "      <td>Community absolutely agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MSNBC</td>\n",
       "      <td>https://www.allsides.com/news-source/msnbc</td>\n",
       "      <td>left</td>\n",
       "      <td>Community absolutely agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>National Review (News)</td>\n",
       "      <td>https://www.allsides.com/news-source/national-...</td>\n",
       "      <td>right-center</td>\n",
       "      <td>Community strongly agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>National Review (Opinion)</td>\n",
       "      <td>https://www.allsides.com/news-source/national-...</td>\n",
       "      <td>right</td>\n",
       "      <td>Community agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NBC News Digital</td>\n",
       "      <td>https://www.allsides.com/news-source/nbc-news-...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>Community somewhat agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>New York Post (News)</td>\n",
       "      <td>https://www.allsides.com/news-source/new-york-...</td>\n",
       "      <td>right-center</td>\n",
       "      <td>Community agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>New York Times (News)</td>\n",
       "      <td>https://www.allsides.com/news-source/new-york-...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>Community somewhat disagrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>New York Times (Opinion)</td>\n",
       "      <td>https://www.allsides.com/news-source/new-york-...</td>\n",
       "      <td>left</td>\n",
       "      <td>Community absolutely agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Newsmax (News)</td>\n",
       "      <td>https://www.allsides.com/news-source/newsmax</td>\n",
       "      <td>right</td>\n",
       "      <td>Community somewhat agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Newsmax (Opinion)</td>\n",
       "      <td>https://www.allsides.com/news-source/newsmax-o...</td>\n",
       "      <td>right</td>\n",
       "      <td>Community absolutely agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NewsNation</td>\n",
       "      <td>https://www.allsides.com/news-source/newsnatio...</td>\n",
       "      <td>center</td>\n",
       "      <td>Community somewhat agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Newsweek</td>\n",
       "      <td>https://www.allsides.com/news-source/newsweek</td>\n",
       "      <td>center</td>\n",
       "      <td>Community disagrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NPR (Online News)</td>\n",
       "      <td>https://www.allsides.com/news-source/npr-media...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>Community somewhat disagrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NPR (Opinion)</td>\n",
       "      <td>https://www.allsides.com/news-source/npr-edito...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>Community somewhat disagrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Politico</td>\n",
       "      <td>https://www.allsides.com/news-source/politico-...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>Community somewhat disagrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Reason</td>\n",
       "      <td>https://www.allsides.com/news-source/reason</td>\n",
       "      <td>center</td>\n",
       "      <td>Community somewhat agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>https://www.allsides.com/news-source/reuters</td>\n",
       "      <td>center</td>\n",
       "      <td>Community agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Slate</td>\n",
       "      <td>https://www.allsides.com/news-source/slate</td>\n",
       "      <td>left</td>\n",
       "      <td>Community strongly agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>The American Spectator</td>\n",
       "      <td>https://www.allsides.com/news-source/american-...</td>\n",
       "      <td>right</td>\n",
       "      <td>Community strongly agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>The Atlantic</td>\n",
       "      <td>https://www.allsides.com/news-source/atlantic</td>\n",
       "      <td>left</td>\n",
       "      <td>Community agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The Blaze</td>\n",
       "      <td>https://www.allsides.com/news-source/theblaze-...</td>\n",
       "      <td>right</td>\n",
       "      <td>Community somewhat agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>The Daily Caller</td>\n",
       "      <td>https://www.allsides.com/news-source/daily-caller</td>\n",
       "      <td>right</td>\n",
       "      <td>Community strongly agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>The Daily Wire</td>\n",
       "      <td>https://www.allsides.com/news-source/daily-wire</td>\n",
       "      <td>right</td>\n",
       "      <td>Community strongly agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>The Economist</td>\n",
       "      <td>https://www.allsides.com/news-source/economist</td>\n",
       "      <td>left-center</td>\n",
       "      <td>Community disagrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>The Epoch Times</td>\n",
       "      <td>https://www.allsides.com/news-source/epoch-tim...</td>\n",
       "      <td>right-center</td>\n",
       "      <td>Community agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>The Federalist</td>\n",
       "      <td>https://www.allsides.com/news-source/federalist</td>\n",
       "      <td>right</td>\n",
       "      <td>Community strongly agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>The Guardian</td>\n",
       "      <td>https://www.allsides.com/news-source/guardian</td>\n",
       "      <td>left</td>\n",
       "      <td>Community agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>The Hill</td>\n",
       "      <td>https://www.allsides.com/news-source/hill-medi...</td>\n",
       "      <td>center</td>\n",
       "      <td>Community somewhat disagrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>The Intercept</td>\n",
       "      <td>https://www.allsides.com/news-source/intercept</td>\n",
       "      <td>left</td>\n",
       "      <td>Community strongly agrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>The New Yorker</td>\n",
       "      <td>https://www.allsides.com/news-source/new-yorker</td>\n",
       "      <td>left</td>\n",
       "      <td>Community absolutely agrees.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    News Source  \\\n",
       "0             ABC News (Online)   \n",
       "1                      AlterNet   \n",
       "2              Associated Press   \n",
       "3   Associated Press Fact Check   \n",
       "4                         Axios   \n",
       "5                      BBC News   \n",
       "6                     Bloomberg   \n",
       "7                Breitbart News   \n",
       "8              Business Insider   \n",
       "9                 BuzzFeed News   \n",
       "10            CBS News (Online)   \n",
       "11    Christian Science Monitor   \n",
       "12                  CNN Digital   \n",
       "13                  Daily Beast   \n",
       "14                   Daily Mail   \n",
       "15               Democracy Now!   \n",
       "16                       Forbes   \n",
       "17           Fox News (Opinion)   \n",
       "18             Fox News Digital   \n",
       "19                     HuffPost   \n",
       "20                 Mother Jones   \n",
       "21                        MSNBC   \n",
       "22       National Review (News)   \n",
       "23    National Review (Opinion)   \n",
       "24             NBC News Digital   \n",
       "25         New York Post (News)   \n",
       "26        New York Times (News)   \n",
       "27     New York Times (Opinion)   \n",
       "28               Newsmax (News)   \n",
       "29            Newsmax (Opinion)   \n",
       "30                   NewsNation   \n",
       "31                     Newsweek   \n",
       "32            NPR (Online News)   \n",
       "33                NPR (Opinion)   \n",
       "34                     Politico   \n",
       "35                       Reason   \n",
       "36                      Reuters   \n",
       "37                        Slate   \n",
       "38       The American Spectator   \n",
       "39                 The Atlantic   \n",
       "40                    The Blaze   \n",
       "41             The Daily Caller   \n",
       "42               The Daily Wire   \n",
       "43                The Economist   \n",
       "44              The Epoch Times   \n",
       "45               The Federalist   \n",
       "46                 The Guardian   \n",
       "47                     The Hill   \n",
       "48                The Intercept   \n",
       "49               The New Yorker   \n",
       "\n",
       "                                                 Link AllSides Bias Rating  \\\n",
       "0   https://www.allsides.com/news-source/abc-news-...          left-center   \n",
       "1   https://www.allsides.com/news-source/alternet-...                 left   \n",
       "2   https://www.allsides.com/news-source/associate...                 left   \n",
       "3   https://www.allsides.com/news-source/ap-fact-c...          left-center   \n",
       "4          https://www.allsides.com/news-source/axios          left-center   \n",
       "5   https://www.allsides.com/news-source/bbc-news-...               center   \n",
       "6   https://www.allsides.com/news-source/bloomberg...          left-center   \n",
       "7      https://www.allsides.com/news-source/breitbart                right   \n",
       "8   https://www.allsides.com/news-source/insider-m...          left-center   \n",
       "9   https://www.allsides.com/news-source/buzzfeed-...                 left   \n",
       "10  https://www.allsides.com/news-source/cbs-news-...          left-center   \n",
       "11  https://www.allsides.com/news-source/christian...               center   \n",
       "12  https://www.allsides.com/news-source/cnn-media...          left-center   \n",
       "13  https://www.allsides.com/news-source/daily-bea...                 left   \n",
       "14    https://www.allsides.com/news-source/daily-mail                right   \n",
       "15  https://www.allsides.com/news-source/democracy...                 left   \n",
       "16        https://www.allsides.com/news-source/forbes               center   \n",
       "17  https://www.allsides.com/news-source/fox-news-...                right   \n",
       "18  https://www.allsides.com/news-source/fox-news-...                right   \n",
       "19  https://www.allsides.com/news-source/huffpost-...                 left   \n",
       "20  https://www.allsides.com/news-source/mother-jo...                 left   \n",
       "21         https://www.allsides.com/news-source/msnbc                 left   \n",
       "22  https://www.allsides.com/news-source/national-...         right-center   \n",
       "23  https://www.allsides.com/news-source/national-...                right   \n",
       "24  https://www.allsides.com/news-source/nbc-news-...          left-center   \n",
       "25  https://www.allsides.com/news-source/new-york-...         right-center   \n",
       "26  https://www.allsides.com/news-source/new-york-...          left-center   \n",
       "27  https://www.allsides.com/news-source/new-york-...                 left   \n",
       "28       https://www.allsides.com/news-source/newsmax                right   \n",
       "29  https://www.allsides.com/news-source/newsmax-o...                right   \n",
       "30  https://www.allsides.com/news-source/newsnatio...               center   \n",
       "31      https://www.allsides.com/news-source/newsweek               center   \n",
       "32  https://www.allsides.com/news-source/npr-media...          left-center   \n",
       "33  https://www.allsides.com/news-source/npr-edito...          left-center   \n",
       "34  https://www.allsides.com/news-source/politico-...          left-center   \n",
       "35        https://www.allsides.com/news-source/reason               center   \n",
       "36       https://www.allsides.com/news-source/reuters               center   \n",
       "37         https://www.allsides.com/news-source/slate                 left   \n",
       "38  https://www.allsides.com/news-source/american-...                right   \n",
       "39      https://www.allsides.com/news-source/atlantic                 left   \n",
       "40  https://www.allsides.com/news-source/theblaze-...                right   \n",
       "41  https://www.allsides.com/news-source/daily-caller                right   \n",
       "42    https://www.allsides.com/news-source/daily-wire                right   \n",
       "43     https://www.allsides.com/news-source/economist          left-center   \n",
       "44  https://www.allsides.com/news-source/epoch-tim...         right-center   \n",
       "45    https://www.allsides.com/news-source/federalist                right   \n",
       "46      https://www.allsides.com/news-source/guardian                 left   \n",
       "47  https://www.allsides.com/news-source/hill-medi...               center   \n",
       "48     https://www.allsides.com/news-source/intercept                 left   \n",
       "49    https://www.allsides.com/news-source/new-yorker                 left   \n",
       "\n",
       "               Community feedback  \n",
       "0      Community strongly agrees.  \n",
       "1    Community absolutely agrees.  \n",
       "2      Community somewhat agrees.  \n",
       "3   Community somewhat disagrees.  \n",
       "4   Community somewhat disagrees.  \n",
       "5      Community somewhat agrees.  \n",
       "6   Community somewhat disagrees.  \n",
       "7    Community absolutely agrees.  \n",
       "8   Community somewhat disagrees.  \n",
       "9      Community strongly agrees.  \n",
       "10     Community somewhat agrees.  \n",
       "11  Community somewhat disagrees.  \n",
       "12     Community somewhat agrees.  \n",
       "13   Community absolutely agrees.  \n",
       "14              Community agrees.  \n",
       "15   Community absolutely agrees.  \n",
       "16     Community somewhat agrees.  \n",
       "17   Community absolutely agrees.  \n",
       "18     Community somewhat agrees.  \n",
       "19              Community agrees.  \n",
       "20   Community absolutely agrees.  \n",
       "21   Community absolutely agrees.  \n",
       "22     Community strongly agrees.  \n",
       "23              Community agrees.  \n",
       "24     Community somewhat agrees.  \n",
       "25              Community agrees.  \n",
       "26  Community somewhat disagrees.  \n",
       "27   Community absolutely agrees.  \n",
       "28     Community somewhat agrees.  \n",
       "29   Community absolutely agrees.  \n",
       "30     Community somewhat agrees.  \n",
       "31           Community disagrees.  \n",
       "32  Community somewhat disagrees.  \n",
       "33  Community somewhat disagrees.  \n",
       "34  Community somewhat disagrees.  \n",
       "35     Community somewhat agrees.  \n",
       "36              Community agrees.  \n",
       "37     Community strongly agrees.  \n",
       "38     Community strongly agrees.  \n",
       "39              Community agrees.  \n",
       "40     Community somewhat agrees.  \n",
       "41     Community strongly agrees.  \n",
       "42     Community strongly agrees.  \n",
       "43           Community disagrees.  \n",
       "44              Community agrees.  \n",
       "45     Community strongly agrees.  \n",
       "46              Community agrees.  \n",
       "47  Community somewhat disagrees.  \n",
       "48     Community strongly agrees.  \n",
       "49   Community absolutely agrees.  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(options = chrome_options)\n",
    "\n",
    "\n",
    "# driver.get('https://www.allsides.com/media-bias/ratings')\n",
    "\n",
    "file_path = \"/media/himel/Data/Documents/Academic/Phd_Prep/Qbias/Scraper/Media Bias Ratings _ AllSides.html\"\n",
    "driver.get(\"file://\" + file_path)\n",
    "\n",
    "main_table = driver.find_element(By.XPATH, \"//*[@id=\\\"content\\\"]/div/div[2]/table[1]/tbody\") # table body\n",
    "\n",
    "rows = main_table.find_elements(By.TAG_NAME, \"tr\")\n",
    "columns = [\"News Source\", \"Link\", \"AllSides Bias Rating\", \"Community feedback\" ]\n",
    "\n",
    "data = []\n",
    "for i in rows:\n",
    "    entry = i.find_elements(By.TAG_NAME, \"td\")\n",
    "    news_source = entry[0].find_element(By.TAG_NAME, \"a\").text\n",
    "    link = entry[0].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "    bias_rating = entry[1].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\").split('/')[-1]\n",
    "    communtiy_feedback = entry[3].find_element(By.CLASS_NAME, \"commtext\").text\n",
    "    data.append([news_source, link, bias_rating, communtiy_feedback])\n",
    "driver.quit()\n",
    "df  = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b272ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"allsides_news_source_bias_ratings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a153cf31-4c05-4b1c-8699-60ab5630dcd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Retrieve Article Links for Crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1389d55b-9b73-42a8-83f9-a10b26caa7e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ProtocolError",
     "evalue": "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRemoteDisconnected\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/http/client.py:1428\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1427\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/http/client.py:300\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[32m    298\u001b[39m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[32m    299\u001b[39m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[33m\"\u001b[39m\u001b[33mRemote end closed connection without\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    301\u001b[39m                              \u001b[33m\"\u001b[39m\u001b[33m response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mRemoteDisconnected\u001b[39m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mProtocolError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m     entry = i.find_elements(By.TAG_NAME, \u001b[33m\"\u001b[39m\u001b[33mtd\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m     link = entry[\u001b[32m0\u001b[39m].find_element(By.TAG_NAME, \u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     links.append(\u001b[43mlink\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_attribute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhref\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     33\u001b[39m WebDriverWait(driver, \u001b[32m20\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# retrieve links for other pages\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/site-packages/selenium/webdriver/remote/webelement.py:231\u001b[39m, in \u001b[36mWebElement.get_attribute\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m getAttribute_js \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    230\u001b[39m     _load_js()\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m attribute_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_script\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/* getAttribute */return (\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgetAttribute_js\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m).apply(null, arguments);\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m attribute_value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:528\u001b[39m, in \u001b[36mWebDriver.execute_script\u001b[39m\u001b[34m(self, script, *args)\u001b[39m\n\u001b[32m    525\u001b[39m converted_args = \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[32m    526\u001b[39m command = Command.W3C_EXECUTE_SCRIPT\n\u001b[32m--> \u001b[39m\u001b[32m528\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscript\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43margs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverted_args\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:427\u001b[39m, in \u001b[36mWebDriver.execute\u001b[39m\u001b[34m(self, driver_command, params)\u001b[39m\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msessionId\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m    425\u001b[39m         params[\u001b[33m\"\u001b[39m\u001b[33msessionId\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.session_id\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcommand_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[32m    429\u001b[39m     \u001b[38;5;28mself\u001b[39m.error_handler.check_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/site-packages/selenium/webdriver/remote/remote_connection.py:404\u001b[39m, in \u001b[36mRemoteConnection.execute\u001b[39m\u001b[34m(self, command, params)\u001b[39m\n\u001b[32m    402\u001b[39m trimmed = \u001b[38;5;28mself\u001b[39m._trim_large_entries(params)\n\u001b[32m    403\u001b[39m LOGGER.debug(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, command_info[\u001b[32m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/site-packages/selenium/webdriver/remote/remote_connection.py:428\u001b[39m, in \u001b[36mRemoteConnection._request\u001b[39m\u001b[34m(self, method, url, body)\u001b[39m\n\u001b[32m    425\u001b[39m     body = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client_config.keep_alive:\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    429\u001b[39m     statuscode = response.status\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/site-packages/urllib3/_request_methods.py:143\u001b[39m, in \u001b[36mRequestMethods.request\u001b[39m\u001b[34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request_encode_url(\n\u001b[32m    136\u001b[39m         method,\n\u001b[32m    137\u001b[39m         url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m         **urlopen_kw,\n\u001b[32m    141\u001b[39m     )\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43murlopen_kw\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/site-packages/urllib3/_request_methods.py:278\u001b[39m, in \u001b[36mRequestMethods.request_encode_body\u001b[39m\u001b[34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[39m\n\u001b[32m    274\u001b[39m     extra_kw[\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m].setdefault(\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m, content_type)\n\u001b[32m    276\u001b[39m extra_kw.update(urlopen_kw)\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/site-packages/urllib3/poolmanager.py:443\u001b[39m, in \u001b[36mPoolManager.urlopen\u001b[39m\u001b[34m(self, method, url, redirect, **kw)\u001b[39m\n\u001b[32m    441\u001b[39m     response = conn.urlopen(method, url, **kw)\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/site-packages/urllib3/connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_e, (\u001b[38;5;167;01mOSError\u001b[39;00m, HTTPException)):\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n\u001b[32m    846\u001b[39m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/site-packages/urllib3/util/retry.py:474\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m error \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_read_error(error):\n\u001b[32m    472\u001b[39m     \u001b[38;5;66;03m# Read retry?\u001b[39;00m\n\u001b[32m    473\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    476\u001b[39m         read -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/site-packages/urllib3/util/util.py:38\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m value.__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/http/client.py:1428\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1426\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1430\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ucr-env/lib/python3.12/http/client.py:300\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    296\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mreply:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mrepr\u001b[39m(line))\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[32m    298\u001b[39m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[32m    299\u001b[39m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[33m\"\u001b[39m\u001b[33mRemote end closed connection without\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    301\u001b[39m                              \u001b[33m\"\u001b[39m\u001b[33m response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    303\u001b[39m     version, status, reason = line.split(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[32m2\u001b[39m)\n",
      "\u001b[31mProtocolError\u001b[39m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
     ]
    }
   ],
   "source": [
    "# assemble list of links to all articles\n",
    "links = []\n",
    "\n",
    "# interact with cookie terms\n",
    "# chrome_path = r'driver/chromedriver' #path from 'which chromedriver'\n",
    "# chrome_options = Options()\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "# chrome_options.add_argument(\"--headless\") # open chrome in background\n",
    "# driver = webdriver.Chrome(service=serv, options=chrome_options)\n",
    "driver = webdriver.Chrome(options = chrome_options)\n",
    "\n",
    "driver.get('https://www.allsides.com/headline-roundups')\n",
    "wait = WebDriverWait(driver, 10)\n",
    "# wait.until(EC.element_to_be_clickable((By.CLASS_NAME, 'css-47sehv')))\n",
    "\n",
    "# ele = driver.find_element(By.CLASS_NAME, \"css-47sehv\")\n",
    "# ele.click()\n",
    "\n",
    "# retireve number of pages \n",
    "last_page_button = driver.find_element(By.CLASS_NAME, \"pager-last\")\n",
    "link_last_page = last_page_button.find_elements(By.TAG_NAME, \"a\")\n",
    "t = link_last_page[0].get_attribute(\"href\")\n",
    "last_page_index = int(t[-3:])\n",
    "\n",
    "# retrieve links from start page\n",
    "main_table = driver.find_element(By.XPATH, \"//*[@id=\\\"block-views-de37fa32ea86f5545eb9b7722977a70d\\\"]/div/div[2]/table/tbody\") # table body\n",
    "\n",
    "rows = main_table.find_elements(By.TAG_NAME, \"tr\")\n",
    "for i in rows:\n",
    "    entry = i.find_elements(By.TAG_NAME, \"td\")\n",
    "    link = entry[0].find_element(By.TAG_NAME, \"a\")\n",
    "    links.append(link.get_attribute(\"href\"))\n",
    "WebDriverWait(driver, 20)\n",
    "\n",
    "# retrieve links for other pages\n",
    "for page in tqdm(range(2,last_page_index+1)):   # set to max number of pages\n",
    "    driver.get(\"https://www.allsides.com/headline-roundups?page=\"+str(page))\n",
    "    WebDriverWait(driver, 20)\n",
    "    main_table = driver.find_element(By.XPATH, \"//*[@id=\\\"block-views-de37fa32ea86f5545eb9b7722977a70d\\\"]/div/div[2]/table/tbody\") # table body\n",
    "\n",
    "    rows = main_table.find_elements(By.TAG_NAME, \"tr\")\n",
    "    for i in rows:\n",
    "        entry = i.find_elements(By.TAG_NAME, \"td\")\n",
    "        link = entry[0].find_element(By.TAG_NAME, \"a\")\n",
    "        links.append(link.get_attribute(\"href\"))\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a6ff8a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10547"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d21eb71b-45c5-40df-b103-7bca92a26096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports links as pickle file\n",
    "with open(\"linklist_allsides_news.pickle\", \"wb\") as f:\n",
    "    pickle.dump(links, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e39f557-5a25-4159-b7ef-7d1e5d06faa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports links as csv\n",
    "with open(\"linklist_allsides_news.csv\", \"w\") as f:\n",
    "    for line in links:\n",
    "        print(line, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411f5734-5415-45ac-ad47-edad75ceeb8f",
   "metadata": {},
   "source": [
    "## Retrieve Articles\n",
    "This section of the crawler retrieves all available news articles from AllSides along with the available information and bias tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fde818ff-8d37-4e5e-bd97-b567414ec9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions that assert the existence of \n",
    "def check_exists_by_xpath(xpath):\n",
    "    try:\n",
    "        driver.find_elements(By.XPATH, xpath)[0]\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_exists_by_class(inp):\n",
    "    try:\n",
    "        driver.find_elements(By.CLASS_NAME, inp)[0]\n",
    "    except:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "068d8b13-8ad6-47e9-acba-94020b6900a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10547"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load link list from pickle file\n",
    "with open(\"linklist_allsides_news.pickle\", \"rb\") as f:\n",
    "    links = pickle.load(f)\n",
    "\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "895787da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.allsides.com/story/politics-foreign-aid-package-divides-house-senate-republicans\n",
      "https://www.allsides.com/story/abortion-fda-expands-abortion-pill-access\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "n_done = 2\n",
    "start = 0 + batch_size*n_done\n",
    "end = start+batch_size\n",
    "links = links[start:end]\n",
    "print(links[0])\n",
    "print(links[-1])\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4a05fcc-8ba5-45fa-a79a-3da26b3a12c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1000/1000 [1:52:41<00:00,  6.76s/it]\n"
     ]
    }
   ],
   "source": [
    "# list for results \n",
    "data = []\n",
    "wait_time = 0.5\n",
    "WINDOW_SIZE = \"1920,1080\"\n",
    "CHROME_PATH = '/usr/bin/google-chrome'\n",
    "CHROMEDRIVER_PATH = '/media/himel/Data/Documents/Academic/Phd_Prep/chromedriver-linux64/chromedriver'\n",
    "# retrieve information from articles in list of links\n",
    "for li in tqdm(links):\n",
    "    time.sleep(wait_time)\n",
    "    # driver = webdriver.Chrome(service=serv, options=chrome_options)\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    # value got from: https://useragentstring.com/\n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36\")\n",
    "    # chrome_options.add_argument(\"--window-size=%s\" % WINDOW_SIZE)\n",
    "    # chrome_options.binary_location = CHROME_PATH\n",
    "    driver = webdriver.Chrome(\n",
    "        # executable_path=CHROMEDRIVER_PATH, \n",
    "        options = chrome_options\n",
    "                              )\n",
    "\n",
    "    print(li)\n",
    "\n",
    "    # open URL\n",
    "    driver.get(li)\n",
    "\n",
    "    # test headless ui\n",
    "    # driver.get_screenshot_as_file(\"capture.png\")\n",
    "    # driver.close()\n",
    "    # break\n",
    "    \n",
    "    # interact with pop-up window\n",
    "    if check_exists_by_class(\"css-47sehv\"):\n",
    "        ele = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((driver.find_element(By.CLASS_NAME, \"css-47sehv\"))))\n",
    "        ele.click()\n",
    "    else:\n",
    "        print(\"no button\")\n",
    "    \n",
    "    # netral title heading \n",
    "    try:\n",
    "        heading = driver.find_element(By.TAG_NAME, \"h1\").text\n",
    "        description = '\\n'.join([p.text for p in driver.find_element(By.CLASS_NAME, \"story-id-page-description\").find_elements(By.TAG_NAME, \"p\")])\n",
    "    except:\n",
    "        print(\"no heading found\")\n",
    "    \n",
    "    print(heading)\n",
    "    \n",
    "    # date\n",
    "    try:\n",
    "        date = driver.find_element(By.CLASS_NAME, \"date-display-single\").text\n",
    "    except:\n",
    "        date = \"\"\n",
    "    \n",
    "    # tags\n",
    "    try:\n",
    "        tags = [a.text for a in driver.find_element(By.CLASS_NAME, \"page-tags\").find_elements(By.TAG_NAME, \"a\")]\n",
    "    except:\n",
    "        tags = \"\"\n",
    "        \n",
    "    \n",
    "    # define XPATH inforamtion for article divs\n",
    "    # divs = [\"/html/body/div[4]/div/div/div/div[4]/div/div/div/div[1]\", \"/html/body/div[4]/div/div/div/div[4]/div/div/div/div[2]\", \"/html/body/div[4]/div/div/div/div[4]/div/div/div/div[3]\"]\n",
    "    divs = [\"/html/body/div[2]/div/div/div[2]/div[4]/div/div/div/div[1]\", \n",
    "            \"/html/body/div[2]/div/div/div[2]/div[4]/div/div/div/div[2]\", \n",
    "            \"/html/body/div[2]/div/div/div[2]/div[4]/div/div/div/div[3]\"]\n",
    "   \n",
    "\n",
    "\n",
    "    # access information in article divs\n",
    "    for d in divs:\n",
    "        if check_exists_by_xpath(d):\n",
    "            div = driver.find_elements(By.XPATH, d)[0]\n",
    "\n",
    "            # check heading element to find out left/center/right. The title contains the bias label that we can retrieve from the text here\n",
    "            try:\n",
    "                cat = div.find_element(By.TAG_NAME, \"h3\").text\n",
    "            except: \n",
    "                print(\"no headline found\")\n",
    "                \n",
    "            # retrieve link to original article\n",
    "            try:\n",
    "                link = div.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                print(link)\n",
    "            except:\n",
    "                print(\"no link found\")\n",
    "                \n",
    "            # left/center/right are shuffled for each article, some roundups have e.g. only left and right articles. \n",
    "            # Thus, we have look to look each article seperately\n",
    "            time.sleep(0.2)\n",
    "            if \"Left\" in cat:\n",
    "                print(\"left\")\n",
    "                try:\n",
    "                    left_heading = div.find_element(By.CLASS_NAME, \"news-title\").text # heading       \n",
    "                except:\n",
    "                    left_heading = \"\"\n",
    "                    print(\"no headline found\")\n",
    "                try:\n",
    "                    left_source = div.find_element(By.CLASS_NAME, \"source-area\").find_element(By.TAG_NAME, \"span\").text #source\n",
    "                except:\n",
    "                    left_source = \"\"\n",
    "                    print(\"no source found\")\n",
    "                try:\n",
    "                    left_text = div.find_element(By.CLASS_NAME, \"news-body\").find_element(By.CLASS_NAME, \"body-contents\").text # news text body-contents\n",
    "                except:\n",
    "                    left_text = \"\"\n",
    "                    print(\"no text found\")\n",
    "                    \n",
    "                # add the article information\n",
    "                data.append({\"url\":link, \"date\":date, \"title\": heading, \"description\": description, \"tags\": tags, \n",
    "                             \"heading\":left_heading, \"source\": left_source, \"text\": left_text, \"bias_rating\": \"left\"})\n",
    "\n",
    "            elif \"Right\" in cat:\n",
    "                print(\"right\")\n",
    "                try:\n",
    "                    right_heading = div.find_element(By.CLASS_NAME, \"news-title\").text # heading\n",
    "                except:\n",
    "                    right_heading = \"\"\n",
    "                    print(\"no headline found\")\n",
    "                try:\n",
    "                    right_source = div.find_element(By.CLASS_NAME, \"source-area\").find_element(By.TAG_NAME, \"span\").text #source \n",
    "                except:\n",
    "                    right_source = \"\"\n",
    "                    print(\"no source found\")\n",
    "                try:\n",
    "                    right_text = div.find_element(By.CLASS_NAME, \"news-body\").find_element(By.CLASS_NAME, \"body-contents\").text # news text\n",
    "                except:\n",
    "                    right_text = \"\"\n",
    "                    print(\"no text found\")\n",
    "                \n",
    "                # add the article information\n",
    "                data.append({\"url\":link, \"date\":date, \"title\": heading, \"description\": description, \"tags\": tags, \n",
    "                             \"heading\":right_heading, \"source\": right_source, \"text\": right_text, \"bias_rating\": \"right\"}) \n",
    "\n",
    "            else:\n",
    "                print(\"center\")\n",
    "                try:\n",
    "                    center_heading = div.find_element(By.CLASS_NAME, \"news-title\").text # heading\n",
    "                except:\n",
    "                    center_heading = \"\"\n",
    "                    print(\"no headline found\")\n",
    "                try:\n",
    "                    center_source = div.find_element(By.CLASS_NAME, \"source-area\").find_element(By.TAG_NAME, \"span\").text #source \n",
    "                except:\n",
    "                    center_source = \"\"\n",
    "                    print(\"no source found\")\n",
    "                try:\n",
    "                    center_text = div.find_element(By.CLASS_NAME, \"news-body\").find_element(By.CLASS_NAME, \"body-contents\").text # news text\n",
    "                except:\n",
    "                    center_text = \"\"\n",
    "                    print(\"no text found\")\n",
    "                    \n",
    "                # add the article information\n",
    "                data.append({\"url\":link, \"date\":date, \"title\": heading, \"description\": description, \"tags\": tags, \n",
    "                             \"heading\":center_heading, \"source\": center_source, \"text\": center_text, \"bias_rating\": \"center\"})\n",
    "        else:\n",
    "            print(\"div not found\")\n",
    "        \n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    # clear output\n",
    "    clear_output()\n",
    "    # added a wait here to assert the scraper runs well\n",
    "    time.sleep(wait_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7bf9ae32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d2b06a89-ddec-4572-ba28-0856fbb4d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists(\"allsides_news_complete.csv\"):\n",
    "    old_df = pd.read_csv(\"allsides_news_complete.csv\", index_col=0)\n",
    "    df = pd.concat([old_df, pd.DataFrame(data)]).reset_index(drop=True)\n",
    "else:\n",
    "    ## convert data to dataframe\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "# export scraped articles\n",
    "df.to_csv(\"allsides_news_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "934a446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1771,)\n",
      "bias_rating\n",
      "left      1864\n",
      "right     1774\n",
      "center    1576\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>heading</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>bias_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://edition.cnn.com/2025/04/11/politics/us...</td>\n",
       "      <td>April 13th, 2025</td>\n",
       "      <td>Trump Orders Military to Control Land on South...</td>\n",
       "      <td>President Donald Trump ordered the US military...</td>\n",
       "      <td>['Defense And Security', 'US-Mexico Border', '...</td>\n",
       "      <td>Trump authorizes military to take control of f...</td>\n",
       "      <td>CNN Digital</td>\n",
       "      <td>President Donald Trump sent a memorandum to fo...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.newsnationnow.com/us-news/immigrat...</td>\n",
       "      <td>April 13th, 2025</td>\n",
       "      <td>Trump Orders Military to Control Land on South...</td>\n",
       "      <td>President Donald Trump ordered the US military...</td>\n",
       "      <td>['Defense And Security', 'US-Mexico Border', '...</td>\n",
       "      <td>White House authorizes military control of lan...</td>\n",
       "      <td>NewsNation</td>\n",
       "      <td>The newest effort from the Trump administratio...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.foxnews.com/politics/trump-orders-...</td>\n",
       "      <td>April 13th, 2025</td>\n",
       "      <td>Trump Orders Military to Control Land on South...</td>\n",
       "      <td>President Donald Trump ordered the US military...</td>\n",
       "      <td>['Defense And Security', 'US-Mexico Border', '...</td>\n",
       "      <td>Trump orders military to take control of feder...</td>\n",
       "      <td>Fox News Digital</td>\n",
       "      <td>The U.S. military will take control of a strip...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://nypost.com/2025/04/12/world-news/iran-...</td>\n",
       "      <td>April 12th, 2025</td>\n",
       "      <td>Iran and US Conduct Preliminary Nuclear Talks ...</td>\n",
       "      <td>Envoys from Iran and the US met in Oman to com...</td>\n",
       "      <td>['Foreign Policy', 'Donald Trump', 'Iran', 'Nu...</td>\n",
       "      <td>Iran says indirect talks begin with US envoy...</td>\n",
       "      <td>New York Post (News)</td>\n",
       "      <td>Iran and the United States will hold more nego...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.bbc.com/news/articles/c4g2eggzvjgo</td>\n",
       "      <td>April 12th, 2025</td>\n",
       "      <td>Iran and US Conduct Preliminary Nuclear Talks ...</td>\n",
       "      <td>Envoys from Iran and the US met in Oman to com...</td>\n",
       "      <td>['Foreign Policy', 'Donald Trump', 'Iran', 'Nu...</td>\n",
       "      <td>Iran says it wants 'fair agreement' as nuclear...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>Iran and the United States have begun talks in...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5209</th>\n",
       "      <td>https://www.washingtonpost.com/politics/2023/1...</td>\n",
       "      <td>November 2nd, 2023</td>\n",
       "      <td>Can We Trust Gaza Death Toll Numbers?</td>\n",
       "      <td>Gaza's Hamas-run health ministry says nearly 9...</td>\n",
       "      <td>['Middle East', 'Israel Hamas Violence', 'Gaza...</td>\n",
       "      <td>Bidens dismissal of the reported Palestinian ...</td>\n",
       "      <td>Washington Post Fact Check</td>\n",
       "      <td>The Hamas attack on Israel on Oct. 7 killed mo...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5210</th>\n",
       "      <td>https://www.wsj.com/livecoverage/israel-hamas-...</td>\n",
       "      <td>November 2nd, 2023</td>\n",
       "      <td>Can We Trust Gaza Death Toll Numbers?</td>\n",
       "      <td>Gaza's Hamas-run health ministry says nearly 9...</td>\n",
       "      <td>['Middle East', 'Israel Hamas Violence', 'Gaza...</td>\n",
       "      <td>Gaza Death Toll Rises to More Than 9,000, Loca...</td>\n",
       "      <td>Wall Street Journal (News)</td>\n",
       "      <td>The Hamas-controlled Gaza health authorities s...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5211</th>\n",
       "      <td>https://www.thedailybeast.com/elon-musk-spins-...</td>\n",
       "      <td>November 1st, 2023</td>\n",
       "      <td>Musk Says Twitter Suppressed Republicans at '1...</td>\n",
       "      <td>Tesla CEO and X (formerly Twitter) owner Elon ...</td>\n",
       "      <td>['Media Bias', 'Social Media', 'Twitter', 'X',...</td>\n",
       "      <td>Elon Musk Goes Buck Wild in Really, Really Lon...</td>\n",
       "      <td>Daily Beast</td>\n",
       "      <td>Elon Musk made his fourth appearance Tuesday o...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5212</th>\n",
       "      <td>https://www.newsweek.com/musk-tells-rogan-twit...</td>\n",
       "      <td>November 1st, 2023</td>\n",
       "      <td>Musk Says Twitter Suppressed Republicans at '1...</td>\n",
       "      <td>Tesla CEO and X (formerly Twitter) owner Elon ...</td>\n",
       "      <td>['Media Bias', 'Social Media', 'Twitter', 'X',...</td>\n",
       "      <td>Musk Tells Rogan Twitter 'Suppressed' Republic...</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>Elon Musk said that conservative users of X, f...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>https://nypost.com/2023/11/01/business/elon-mu...</td>\n",
       "      <td>November 1st, 2023</td>\n",
       "      <td>Musk Says Twitter Suppressed Republicans at '1...</td>\n",
       "      <td>Tesla CEO and X (formerly Twitter) owner Elon ...</td>\n",
       "      <td>['Media Bias', 'Social Media', 'Twitter', 'X',...</td>\n",
       "      <td>Elon Musk says George Soros fundamentally hat...</td>\n",
       "      <td>New York Post (News)</td>\n",
       "      <td>Billionaire Elon Musk launched a new attack ag...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5214 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url                date  \\\n",
       "0     https://edition.cnn.com/2025/04/11/politics/us...    April 13th, 2025   \n",
       "1     https://www.newsnationnow.com/us-news/immigrat...    April 13th, 2025   \n",
       "2     https://www.foxnews.com/politics/trump-orders-...    April 13th, 2025   \n",
       "3     https://nypost.com/2025/04/12/world-news/iran-...    April 12th, 2025   \n",
       "4        https://www.bbc.com/news/articles/c4g2eggzvjgo    April 12th, 2025   \n",
       "...                                                 ...                 ...   \n",
       "5209  https://www.washingtonpost.com/politics/2023/1...  November 2nd, 2023   \n",
       "5210  https://www.wsj.com/livecoverage/israel-hamas-...  November 2nd, 2023   \n",
       "5211  https://www.thedailybeast.com/elon-musk-spins-...  November 1st, 2023   \n",
       "5212  https://www.newsweek.com/musk-tells-rogan-twit...  November 1st, 2023   \n",
       "5213  https://nypost.com/2023/11/01/business/elon-mu...  November 1st, 2023   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Trump Orders Military to Control Land on South...   \n",
       "1     Trump Orders Military to Control Land on South...   \n",
       "2     Trump Orders Military to Control Land on South...   \n",
       "3     Iran and US Conduct Preliminary Nuclear Talks ...   \n",
       "4     Iran and US Conduct Preliminary Nuclear Talks ...   \n",
       "...                                                 ...   \n",
       "5209              Can We Trust Gaza Death Toll Numbers?   \n",
       "5210              Can We Trust Gaza Death Toll Numbers?   \n",
       "5211  Musk Says Twitter Suppressed Republicans at '1...   \n",
       "5212  Musk Says Twitter Suppressed Republicans at '1...   \n",
       "5213  Musk Says Twitter Suppressed Republicans at '1...   \n",
       "\n",
       "                                            description  \\\n",
       "0     President Donald Trump ordered the US military...   \n",
       "1     President Donald Trump ordered the US military...   \n",
       "2     President Donald Trump ordered the US military...   \n",
       "3     Envoys from Iran and the US met in Oman to com...   \n",
       "4     Envoys from Iran and the US met in Oman to com...   \n",
       "...                                                 ...   \n",
       "5209  Gaza's Hamas-run health ministry says nearly 9...   \n",
       "5210  Gaza's Hamas-run health ministry says nearly 9...   \n",
       "5211  Tesla CEO and X (formerly Twitter) owner Elon ...   \n",
       "5212  Tesla CEO and X (formerly Twitter) owner Elon ...   \n",
       "5213  Tesla CEO and X (formerly Twitter) owner Elon ...   \n",
       "\n",
       "                                                   tags  \\\n",
       "0     ['Defense And Security', 'US-Mexico Border', '...   \n",
       "1     ['Defense And Security', 'US-Mexico Border', '...   \n",
       "2     ['Defense And Security', 'US-Mexico Border', '...   \n",
       "3     ['Foreign Policy', 'Donald Trump', 'Iran', 'Nu...   \n",
       "4     ['Foreign Policy', 'Donald Trump', 'Iran', 'Nu...   \n",
       "...                                                 ...   \n",
       "5209  ['Middle East', 'Israel Hamas Violence', 'Gaza...   \n",
       "5210  ['Middle East', 'Israel Hamas Violence', 'Gaza...   \n",
       "5211  ['Media Bias', 'Social Media', 'Twitter', 'X',...   \n",
       "5212  ['Media Bias', 'Social Media', 'Twitter', 'X',...   \n",
       "5213  ['Media Bias', 'Social Media', 'Twitter', 'X',...   \n",
       "\n",
       "                                                heading  \\\n",
       "0     Trump authorizes military to take control of f...   \n",
       "1     White House authorizes military control of lan...   \n",
       "2     Trump orders military to take control of feder...   \n",
       "3     Iran says indirect talks begin with US envoy...   \n",
       "4     Iran says it wants 'fair agreement' as nuclear...   \n",
       "...                                                 ...   \n",
       "5209  Bidens dismissal of the reported Palestinian ...   \n",
       "5210  Gaza Death Toll Rises to More Than 9,000, Loca...   \n",
       "5211  Elon Musk Goes Buck Wild in Really, Really Lon...   \n",
       "5212  Musk Tells Rogan Twitter 'Suppressed' Republic...   \n",
       "5213  Elon Musk says George Soros fundamentally hat...   \n",
       "\n",
       "                          source  \\\n",
       "0                    CNN Digital   \n",
       "1                     NewsNation   \n",
       "2               Fox News Digital   \n",
       "3           New York Post (News)   \n",
       "4                       BBC News   \n",
       "...                          ...   \n",
       "5209  Washington Post Fact Check   \n",
       "5210  Wall Street Journal (News)   \n",
       "5211                 Daily Beast   \n",
       "5212                    Newsweek   \n",
       "5213        New York Post (News)   \n",
       "\n",
       "                                                   text bias_rating  \n",
       "0     President Donald Trump sent a memorandum to fo...        left  \n",
       "1     The newest effort from the Trump administratio...      center  \n",
       "2     The U.S. military will take control of a strip...       right  \n",
       "3     Iran and the United States will hold more nego...       right  \n",
       "4     Iran and the United States have begun talks in...      center  \n",
       "...                                                 ...         ...  \n",
       "5209  The Hamas attack on Israel on Oct. 7 killed mo...        left  \n",
       "5210  The Hamas-controlled Gaza health authorities s...      center  \n",
       "5211  Elon Musk made his fourth appearance Tuesday o...        left  \n",
       "5212  Elon Musk said that conservative users of X, f...      center  \n",
       "5213  Billionaire Elon Musk launched a new attack ag...       right  \n",
       "\n",
       "[5214 rows x 9 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"allsides_news_complete.csv\", index_col=0)\n",
    "print(df.title.unique().shape)\n",
    "print(df.bias_rating.value_counts())\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
